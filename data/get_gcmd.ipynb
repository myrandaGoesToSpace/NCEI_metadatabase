{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook to create a CSV file of all GCMD science keywords and their ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GCMD Science keywords\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attr(attr_name):\n",
    "    attr_list = []\n",
    "    attr_character_string = soup.find_all(attr_name)\n",
    "\n",
    "    for attr in attr_character_string:\n",
    "        attr_list.append(attr.text)\n",
    "\n",
    "    return attr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 URLs because the GCMD keywords take up two pages\n",
    "URL1 = \"https://gcmd.earthdata.nasa.gov/kms/concepts/concept_scheme/sciencekeywords?format=xml\"\n",
    "URL2 = \"https://gcmd.earthdata.nasa.gov/kms/concepts/concept_scheme/sciencekeywords?format=xml&page_num=2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "page1 = requests.get(URL1)\n",
    "page2 = requests.get(URL2)\n",
    "\n",
    "#soup = BeautifulSoup((page1.text, \"lxml\")\n",
    "#soup2 = BeautifulSoup(page2.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup((page1.text + page2.text), \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3464\n"
     ]
    }
   ],
   "source": [
    "# Get concept tags\n",
    "parent_tag = \"concepts\"\n",
    "parents = soup.find_all(parent_tag)\n",
    "print(len(parents))\n",
    "\n",
    "concepts = []\n",
    "for tag in parents:\n",
    "    concept = tag.find_all(\"conceptbrief\")\n",
    "    concepts = concepts + concept\n",
    "    \n",
    "print(len(concepts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3464\n",
      "3464\n"
     ]
    }
   ],
   "source": [
    "gcmd_url = \"https://gcmd.earthdata.nasa.gov/kms/concept/\"\n",
    "\n",
    "labels = []\n",
    "uuids = []\n",
    "for c in concepts:\n",
    "    label = c.attrs['preflabel']\n",
    "    uuid = c.attrs['uuid']\n",
    "    \n",
    "    labels.append(label)\n",
    "    uuids.append(uuid)\n",
    "    \n",
    "print(len(labels))\n",
    "print(len(uuids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEA LEVEL ANOMALY</td>\n",
       "      <td>0fde8353-9773-4948-b206-9c273c2100c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEA SURFACE HEIGHT ANOMALY _SSHA_</td>\n",
       "      <td>3798a6c9-9b39-4e22-bee4-be80d39049fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEA SURFACE SLOPE</td>\n",
       "      <td>52a32bd3-d701-49e1-a827-67b3d96d8e56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEA SURFACE HEIGHT</td>\n",
       "      <td>5c0b448c-7eb4-4e8c-8403-260cbb6114bb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEAN SEA SURFACE</td>\n",
       "      <td>70082342-c777-49e9-88e5-a4a77728d3cc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               label                                  uuid\n",
       "0                  SEA LEVEL ANOMALY  0fde8353-9773-4948-b206-9c273c2100c8\n",
       "1  SEA SURFACE HEIGHT ANOMALY _SSHA_  3798a6c9-9b39-4e22-bee4-be80d39049fe\n",
       "2                  SEA SURFACE SLOPE  52a32bd3-d701-49e1-a827-67b3d96d8e56\n",
       "3                 SEA SURFACE HEIGHT  5c0b448c-7eb4-4e8c-8403-260cbb6114bb\n",
       "4                   MEAN SEA SURFACE  70082342-c777-49e9-88e5-a4a77728d3cc"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pandas dataframe\n",
    "zip_list = list(zip(labels, uuids))\n",
    "df = pd.DataFrame(zip_list, columns = [\"label\", \"uuid\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv\n",
    "df.to_csv(\"gcmd_science_keywords.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
